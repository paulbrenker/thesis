\section{Evaluation} \label{sec:evaluation}

Das folgende Kapitel widmet sich der Interpretation der gewonnenen Erkenntnisse. Dabei sollen diese eingeordnet werden und die Gültigkeit kritisch hinterfragt werden. Ziel ist es, die Bedeutung der Resultate für die Forschungsfragen herauszuarbeiten. Außerdem widmet sich dieses Kapitel Limitationen der Arbeit und Implikationen für zukünftige Forschungsfragen. 

\subsection{Interpretation der Ergebnisse} \label{sec:interpretationderergebnisse}
Das Ziel der \acs{EDA} ist es, die Daten zugänglich zu machen und deren Charakteristiken zu zeigen. Abbildung \ref{fig:totalspecthrownbarplot} zeigt, dass für verschiedene Regeln die Größenordnung der Anzahl der geworfenen Linterregeln stark variiert. Es existieren Regeln die nie geworfen werden und Regeln, von denen über 100.000 Linterfehler aufgezeichnet wurden. Diese Differenzen machen es schwer, die Regeln anhand absoluter Zahlen zu vergleichen.

Es kann beobachtet werden, dass der Datensatz deutlich durch die OpenAPI Spezifikationen von Azure.com beeinflusst ist. Bei den Regeln, die im Azure.com Datensatz nicht ignoriert wurden, ist der Anteil von ausgelösten Fehlern von azure.com OpenAPI Spezifikationen signifikant geringer. Dies bedeutet, dass die Linterregeln, die von Azure.com aktiviert sind, insgesamt weniger ausgelöst werden. Dies hat einen Einfluss auf die Gewichtung der $\text{Relevenz}_\text{Frequenz}$ Bewertung.

Der Ansatz zur Invertierung der Linterergebnisse war nur limitiert erfolgreich. Da der gewählte Ansatz nur für Single Trigger und Multi Trigger Regeln gültig ist, lässt sich kein Priorisierungsmaß von den Invertierungen ableiten. Trotzdem konnten die Linterergebnisse mit den Invertierungen näher beleuchtet werden. Mit dem vorgestellten Algorithmus \ref{alg:invert} zur Invertierung der Linterergebnisse konnten keine Ergebnisse erzielt werden, die sich für alle Regeln eignen. Nur 23 von 40 Regeln sind als Single- oder Multi Trigger Regeln mit dieser Vorgehensweise invertierbar. In der Diskussion dieser Ergebnisse konnte gezeigt werden, dass die durch die Invertierung mögliche Normalisierung der Größe der Spezifikation hilfreich für die Priorisierung ist. Außerdem können mit der Invertierung Aussagen über die Konsistenz der Einhaltung der Regeln innerhalb von Spezifikationen gemacht werden. Diese Informationen tragen zur Einschätzung der Relevanz einer Regel bei. Von den erfolgreich invertierten Regeln sind beim Clustering nur die no-eval-in-markdown und die, die nie ausgelöst wurden in der Kategorie \texttt{error}. Die Diskussion in Abschnitt \ref{sec:auswertungderinvertierung} empfiehlt außerdem, die Regeln oas3-api-servers für die Single-Trigger Regeln und für die Multi-Trigger Regeln no-script-tags-in-markdown zu verwenden. Die Analyse in Abbildung \ref{fig:boxplotcleanmultitrigger} zeigt, dass die Regeln operation-success-response, duplicated-entry-in-enum und array-items dazu tendieren nicht konsistent innerhalb einer Spezifikation Linterfehler auszulösen. Inkonsistente Verursachung ist ein weiterer Grund, diese Regeln höher zu priorisieren. Abgesehen von operation-success-response wurden die Regeln von der Clustereinteilung mit dem \texttt{warn} Schweregrad versehen. Anhand der Analyse zu Abbildung \ref{fig:boxplotcleanmultitrigger} kann man die Implikation ableiten, die Regel operation-success-response nicht als \texttt{hint}, sondern als \texttt{error} zu bewerten.

Die Priorisierungsmaße verwenden beide ausschließlich Wahrheitswerte. Trotz dieser Limitation konnten aussagekräftige Ergebnisse erzeugt werden, die eine datengetriebene Antwort auf \textbf{RQ-2} geben. In Tabelle \ref{tab:combinedweighedprioritized} lassen sich diese Ergebnisse ablesen. In Abbildung \ref{fig:priodistrhist} sind die Verteilungen der Priorisierungen abgebildet. 

Es lassen sich subjektive Unterschiede der Relevanz innerhalb der Regeln eines Schweregrads feststellen, die nicht durch eine datengetriebene Analyse gefunden werden können. Hierzu ist die Einschätzung der Anwender eines Lintertools unersetzlich. Einige Beispiele für solche Differenzen sind:
\begin{itemize}
  \item no-eval-in-markdown und no-script-tag-in-markdown sollen beide verhindern, dass ausführbarer Code in Markdown Feldern der OpenAPI Spezifikation eingefügt wird. Trotzdem werden die Regeln unterschiedlichen Schweregraden zugeordnet. Die subjektive Logik wäre hier, dass semantisch ähnliche Regeln dem gleichen Schweregrad zugeordnet werden.
  \item 15 der 16 Regeln im Schweregrad \texttt{error} werden nie ausgelöst. Der Grund, dass eine Regel nie ausgelöst wird, liegt auch nach subjektiver Ansicht entweder daran, dass die Regel sehr relevant ist oder aber einen extrem seltene Randbedingung beschreibt. Ein Beispiel ist die Diskrepanz zwischen der Regel oas3-server-not-example.com und oas3-callbacks-in-callbacks. Die erste Regel soll verhindern, dass die Server Adresse der Schnittstelle kein Beispielwert sein darf. Ohne diese Information ließe sich keiner der Endpunkte erreichen und die Spezifikation verliert viel an Qualität. Die Regel oas3-callbacks-in-callbacks stellt sicher, dass ein Callback nicht innerhalb eines Callbacks definiert wird. Callbacks werden hauptsächlich für Asynchrone Events wie z.B. in Webhooks und Server Sent Events eingesetzt. Im Rahmen von OpenAPI Spezifikationen wird davon ausgegangen, dass es sich bei Verletzungen dieser Regel um sehr seltene Fälle handelt. Dies kann durch die Tatsache bestätigt werden, dass in keiner Spezifikation eine Selektion für einem möglichen Linterfehler gefunden wurde (siehe \ref{tab:totalthrownerrors}).
  \item Subjektiv spielt auch die Anzahl der möglichen Fehler einer Regel eine Rolle in der Gewichtung der Priorisierung. Regeln die nur einmal pro Spezifikation ausgelöst werden können, betreffen globale Attribute dieser Spezifikation. Dies erhöht die Relevanz. Zudem ist es für Entwickler einfacher Fehler zu beheben, die ausschließlich an einer Stelle behoben werden müssen. Ein weiterer Grund für die höhere Priorisierung solcher Regeln wäre, dass Single Trigger Regeln nicht die API Operationen betreffen können. Ein Beheben dieser Linterfehler führt also nicht zu sogenannten Breaking Changes\footnote{Unter Breaking Changes werden Änderungen an der Schnittstellenspezifikation, die mit früheren Versionen der Spezifikation nicht kompatibel sind bezeichnet.}. 
\end{itemize}

Mit dem Clustering wurde eine Neuverteilung der Schweregrade \texttt{error}, \texttt{warn} und \texttt{hint} auf die Linterregeln mit empirischen Methoden erreicht. Dabei wechseln viele Linterregeln den Schweregrad. Die Belegung der Koeffizienten in Abschnitt \ref{sec:kombinationderverfahren} wurden mit Blick auf die Umverteilung von Schweregraden so festgelegt, dass die Anzahl der Regeln, die nicht demselben Schweregrad zugeordnet werden, wie im Spectral \acs{OAS} Regelwerk, minimal ist. Trotzdem soll auch eine Polarisierung der Regeln in Richtung \texttt{error} und \texttt{warn} erreicht werden. Die neu verteilten Regeln werden fast ausschließlich auf die Schweregrade \texttt{error} und \texttt{hint} verteilt. Nur 4 Regeln werden dem Schweregrad \texttt{warn} zugeordnet. Die meisten Regeln werden um ein Schweregrad Level verschoben oder bleiben auf dem Grad, den sie vorher hatten. Dies bestätigt die Vermutung, dass die Regeln aus dem Spectral \acs{OAS} Regelwerk sinnvoll verteilt waren. Ausschließlich die Regel operation-operationId-unique wurde um zwei Schweregrade von \texttt{hint} nach \texttt{error} verschoben. Diese Regel wurde nie ausgelöst. Die Regel stellt eine eindeutige ID für jede API Operation einer OpenAPI Spezifikation sicher. Die Repriorisierung der Regel als \texttt{error} ist nach Einschätzung des Autors jedoch gerechtfertigt.

Die Neuzuordnung der Linter Schweregrade zu den Regeln beantwortet \textbf{RQ-3} und hilft, die große Anzahl der Regeln mit dem Schweregrad \texttt{warn} zu verringern. Dies reduziert Komplexität und gibt eine klare Vorstellung davon, welche Regeln wichtig sind. Als Entwickler lässt sich mithilfe dieser Neuzuordnung eine Strategie entwickeln, um ein Linting von OpenAPI Spezifikationen mit dem Spectral API Linter für bestehende Projekte zu beginnen. 

Eine Strategie könnte sein, dass in einem ersten Schritt nur Linterfehler mit dem Schweregrad \texttt{error} zum Fehlschlagen einer Pipeline zur statischen Codeanalyse führen. In weiteren Schritten kann die Akzeptanz des Spectral \acs{API} Linters verringert werden, sodass auch Linterfehler mit dem Schweregrad \texttt{warn} und \texttt {hint} zu einem fehlgeschlagenen Linting Prozess führen. 

Die vorgeschlagene Neuverteilung der Linter Schweregrade kann Entwicklern Vertrauen in die Linterregeln geben, da dies Regeln sind, die in den meisten der Spezifikationen des OpenAPI Directories eingehalten wurden. Im OpenAPI Directory sind OpenAPI Spezifikationen von den größten Cloud-Anbietern und vielen anderen großen Tech-Unternehmen. Letztendlich ist die Adoption einer Linting Praxis ein individueller Prozess, der von den spezifischen Anforderungen eines Projektes sowie der Vorlieben der Entwickler abhängt.

\subsection{Validität der Arbeit} \label{sec:validitätdesverfahrens}
  Trotz des sorgsamen Entwurfs der Methodik dieser Arbeit, gibt es Risiken, die die Validität des Verfahrens potenziell einschränken.

  Ein Risiko ist die Hürde der Invertierung der Regeln. Ein Maß aufzustellen, das geworfene Fehler und mögliche Fehler für alle Regeln vergleichen kann, könnte einen großen Mehrwert bringen. Dieses Maß ist für Single Trigger und Multi Trigger Regeln gut zu messen. Für komplexere Regeln, insbesondere Regeln, die Spectrals benutzerdefinierte JavaScript Funktionen nutzen, ist dies nicht messbar. Aufgrund mangelnder Vergleichbarkeit aller Regeln können diese ermittelten Zahlen nicht in die Priorisierung mit einfließen.

  Ein weiteres Risiko ist, dass in der vorgestellten Methode die subjektive Relevanz der Regeln nicht berücksichtigt wird. Entwickler verwenden Linter, um die Schnittstellenqualität zu verbessern \parencite{tomasdottir_adoption_2018}. Im Verfahren kann nicht sichergestellt werden, dass subjektiv relevante Regeln hoch priorisiert werden. Eine weitere Möglichkeit einer hohen Priorisierung einer Regel kann sein, dass diese einen seltenen Ausnahmefall behandelt. Es wird versucht diese Diskrepanzen in der Interpretation der Ergebnisse zu finden und zu diskutieren.

  Die Koeffizienten der Kombination der Priorisierungsmaße sind nicht optimiert. Sie sind aufgrund der gezeigten Ungleichgewichte im Datensatz manuell ausgewählt und stellen eine Einschätzung des Autors dar. In der Zukunft wäre es möglich diese Koeffizienten besser zu gewichten.

  Die Qualitätsanforderungen an die Software \textbf{QR-1} - \textbf{QR-6} wurden in der Entwicklung des Softwaretools implementiert. Dies trägt im Nachhinein zur Konfidenz in das Tool und der Funktionalitäten bei.

\subsection{Zusammenfassung} \label{sec:zusammenfassung}
  In dieser Arbeit wurden 4136 in der Praxis verwendete OpenAPI Spezifikationen mit dem Spectral API Linter und dem Standard Spectral OAS Regelwerk analysiert. Die Linterfehler wurden empirisch ausgewertet, um die Relevanz der Linterregel für die Praxis der Softwareentwicklung herauszufinden. Wir haben die Regeln priorisiert und mithilfe von Methoden für unüberwachtes Lernen eine Neuverteilung der Linter Schweregrade erreicht. Dabei wurde festgestellt, dass die Linterergebnisse durch die Spezifikationen von Azure.com eine Verzerrung im Datensatz besteht. Azure benutzt intern den Spectral Linter und das Spectral \acs{OAS} Regelwerk. Dies zieht den Anteil der Azure.com Linterfehler signifikant nach unten. Da Azure.com Spezifikationen 45 \% des OpenAPI Directory ausmachen, beeinflussen diese die Gesamtwerte. 
  
  Beim Versuch die geworfenen Linterregeln zu invertieren und die Anzahl der True Negatives zu finden ist die gewählte Methodik für einen Teil der Regeln erfolgreich. Für diesen Teil konnten Implikationen abgeleitet werden, die in die Interpretation mit eingeflossen sind. Für zukünftige Arbeiten wird aufgezeigt, dass mit der Invertierung der Linterregeln weitere Informationen für eine Priorisierung der Relevanz gewonnen werden können.
  
  Die Relevanz der Linterregeln wurde mit zwei Priorisierungsmaßen, die sich auf die Existenz von Linterfehlern für eine Spezifikation beschränken, bewertet. Das erste Maß lehnt sich an die \acl{IDF} an. Das zweite Maß bewertet, ob sich Spezifikationen die Linterregeln auslösen, überschneiden. Aus den Priorisierungen wurde eine gewichtete Kombination berechnet. Erstere wurde dabei mit 0,8 viermal so hoch wie die Zweite 0,2 gewichtet. Abschließend wurde anhand der Priorisierungen ein Clustering berechnet, das eine Neuverteilung von Linterschweregraden basierend auf der Relevanz der Regel vorschlägt. Die Aussagekraft der Neubelegung sowie Szenarien der Anwendung der Ergebnisse auf Praxisbeispiele wurden in der Interpretation diskutiert.

\subsection{Ausblick} \label{sec:ausblick}
  Die datengetriebene Untersuchung von Linterregeln hat sich als vielversprechend erwiesen. An einigen Punkten hinterlässt diese Arbeit auch offene Enden.

  Zunächst ist die Invertierung aller Regeln ein Problem, das hier noch nicht gelöst wurde. Der Ansatz die Regeln aufgrund der JSONPath Objekte zu invertieren, war nicht für alle Regeln erfolgreich. Das Lösen dieses Problems für alle Regeln würde bedeuten, dass nicht nur das Auftreten von Linterfehlern, sondern auch die Anzahl der Linterfehler objektiv eingeordnet werden könnten.

  In der Diskussion der Ergebnisse der Invertierungen in Abschnitt \ref{sec:interpretationderergebnisse} wird ein Unterschied zwischen den angewendeten Priorisierungsmaßen und Einschätzungen der invertierungsbasierten Priorisierung gezeigt. Die invertierungsbasierten Priorisierungen können Spezifikationsgrößen normalisieren und die Konsistenz der Einhaltung der Regeln vergleichen. Dies bietet Potenzial für weitergehende Forschung, um die in dieser Arbeit erzeugten Ergebnisse zu verfeinern. Weitergehende Forschungsfragen in diese Richtung könnten wie folgt lauten:

  \begin{itemize}
    \item \textbf{RQ-1(Zukunft):} Wie können Multi-Message Regeln invertiert werden?
    \item \textbf{RQ-2(Zukunft):} Wie trägt Inkonsistenz der Einhaltung von Multi-Trigger und Multi-Message Regeln zur Relevanz der Linterregel bei?
  \end{itemize}

  Eine andere Möglichkeit die Größe der Spezifikation zu normalisieren, wäre, diese an Größenkennziffern der OpenAPI Spezifikation zu messen. Größenkennziffern können zum Beispiel Pfad Objekte oder \acs{API} Operationen sein (Ein Pfad Objekt enthält bis zu 6 API Operationen entsprechend der \acs{HTTP} Methoden, die auf ein Pfad Objekt angewandt werden können). In Abbildung \ref{fig:Operations} werden \acs{API} Operationen als Referenzgröße verwendet. Die Pfad- bzw. Operations Objekte beschreiben die zentrale Funktionalität von OpenAPI Spezifikationen. Multi-Trigger und Multi-Message Regeln betreffen daher immer ein multiples Vielfaches der Größe der OpenAPI Spezifikation. Die Normalisierung wäre daher nicht global für alle Regeln, sondern ausschließlich für Ergebnisse der gleichen Regel. Hierfür bieten sich ebenfalls weitere Forschungsfragen an:

  \begin{itemize}
    \item \textbf{RQ-3(Zukunft):} Wie sieht eine Priorisierung der Linterregeln aus, die die Anzahl der geworfenen Fehler anhand der Spezifikationsgröße normalisiert?
  \end{itemize}

  Wie in Abschnitt \ref{sec:verzerrungdesdatensatzes} gezeigt, liegt eine Verzerrung des Datensatzes in Richtung der Azure.com Spezifikationen und den dort aktivierten Regeln des Spectral \acs{OAS} Regelwerks vor. Diese Verzerrung und mögliche weitere Verzerrungen durch Anbieter, die im APIs.guru OpenAPI Directory viele Spezifikationen zur Verfügung stellen sollten reduziert werden. In der Zukunft können für vergleichbare Studien Verfahren zur Datenvorverarbeitung wie Random Undersampling \parencite{hasanin_effects_2018} in die Datenanalyse Pipeline eingebracht werden. Random Undersampling könnte im Anwendungsbeispiel dieser Arbeit dazu beitragen, die Spezifikationen der größten Anbieter zu verwenden, sodass diese keinen signifikanten Einfluss auf die Linterergebnisse haben. 

  \begin{itemize}
    \item \textbf{RQ-4(Zukunft):} Wie kann die Verzerrung des APIs.guru OpenAPI Directory abgemildert werden, ohne Anbieter auszuschließen?
  \end{itemize}

  Ziel dieser Arbeit ist es, Entwicklern eine Empfehlung für eine Strategie der statischen Codeanalyse für OpenAPI Spezifikationen aufzuzeigen. Das nach empirischer Relevanz neu zugeordnete Regelwerk für Codeanalyse von OpenAPI Spezifikationen zu verwenden, ist Teil zukünftiger Arbeiten. Die OpenAPI Spezifikationen der Firma SAP LeanIX sind frei im Internet verfügbar\footnote{Die Entwicklerdokumentation für das SAP LeanIX \acf{EAM} Tool umfasst OpenAPI Spezifikationen, die mithilfe der SwaggerUI öffentlich zur Verfügung stehen \href{https://eu.leanix.net/openapi-explorer/}{https://eu.leanix.net/openapi-explorer/}.}. Die dort verfügbaren Spezifikationen sind nicht im APIs.guru OpenAPI Directory eingetragen und bieten daher die Möglichkeit die Klassifikation der Linterregeln auf Schweregrade zu verifizieren.
  
  \begin{itemize}
    \item \textbf{RQ-5(Zukunft):} Sind die Ergebnisse der Priorisierung anwendbar auf die OpenAPI Spezifikationen der Firma SAP LeanIX?
  \end{itemize}

  Mit den zukünftigen Forschungsfragen \textbf{RQ-1(Zukunft) - RQ-4(Zukunft)} kann die Methodik dieser Arbeit verfeinert werden. \textbf{RQ-5(Zukunft)} fokussiert sich auf die Anwendung der Ergebnisse dieser Arbeit auf Beispiele aus der Praxis. Diese Ansätze können die Ergebnisse dieser Arbeit in der Zukunft ergänzen und verbessern.
